
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content=“width=800”>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    strongsmall {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
      font-weight: 700
    }

    smalll {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
    }

    stronghuge {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
      font-weight: 700
    }

    huge {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 30px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="sjtu_icon.png">
  <title>Shihao Zou</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link rel="shortcut icon" href="image/favicon.ico" />
  <link rel="bookmark" href="image/favicon.ico" />
  <meta name="google-site-verification" content="3Pi5gRNVZ_uFXQ1gBBx91DHgGFC32ASIPVvSeEiTqz8" />
  <!-- <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'> -->
  <!-- <link rel="stylesheet" type="text/css" href="stylesheet.css"> -->
</head>

<body>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Shihao Zou &nbsp;&nbsp;<font face="KaiTi" size="6">邹世豪</font>
                </name>
              </p>
              <p>I’m a third-year Master student in in School of Computer Science and Engineering, Chongqing University of Technology. Currently I am supervised
                 by Prof. <a href="https://cs.cqut.edu.cn/info/1050/1310.htm">Xianying Huang</a>. Prior to my M.S. study, I earned my Bachelor degree 
                 from Pingdingshan University, Henan, China.
                <p>
                  My research interests include Natural Language Processing(NLP), Emotion Recognition in Conversation(ERC), Multimodal fusion.
                </p>
                <p align=center>
                  <a href="mailto:zou990904@gmail.com">Email: zou990409 [at] gmail.com</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?user=6yLFEsIAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
		   <!-- <a href="https://www.semanticscholar.org/author/47303356">Semantic Scholar</a> &nbsp/&nbsp-->
                  <a href="https://z-yolo.github.io/">Github</a>

                </p>

            </td>
            <td width="20%">
              <img src="image/Shihao.jpg" width="130">
            </td>
          </tr>
        </table>

        <p></p>
        <p></p>
        <p></p>
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>News</heading> &nbsp;<stronghuge>(Paper Accept or Reject, Recording my Progress...)</stronghuge>
              <p>
                <li>
                  <strongsmall>[2019/07/01]</strongsmall> &nbsp;&nbsp;<smalll>1 paper with Prof. Alan Hanjalic accepted
                    by ACM MM19.</smalll><br />
                  
	  <li> <strongsmall>[2023/07/26]</strongsmall> &nbsp;&nbsp;<smalll>1 paper with Prof. Alan Hanjalic submitted to ICCV19.</smalll><br/>
          <li> <strongsmall>[2019/02/25]</strongsmall>&nbsp;&nbsp; <smalll>CVPR boardline reject. Better than AAAI. Revise it and try again! </smalll><br/>
          <li> <strongsmall>[2018/12/24]</strongsmall> &nbsp;&nbsp;<smalll>1 revised paper (from AAAI19) submitted to TNNLS. </smalll><br/>
          <li> <strongsmall>[2018/11/13]</strongsmall> &nbsp;&nbsp;<smalll>1 new paper submitted to CVPR19. </smalll><br/>
          <li> <strongsmall>[2018/11/01]</strongsmall> &nbsp;&nbsp;<smalll>My fisrt paper is regected by AAAI19 :(  Keep going! </smalll><br/>
          <li> <strongsmall>[2018/09/08]</strongsmall> &nbsp;&nbsp;<smalll>My fisrt paper submitted to AAAI19.</smalll><br/> 
         
              </p>
            </td>
          </tr>
        </table> -->

        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Education</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="10%">
              <img src='image/uestc_icon.jpg' width="100">
            </td>

            <td width="75%" valign="middle">
              <p>
                <stronghuge>University of Electronic Science and Technology of China (UESTC), China</stronghuge><br />
                Final-year undergraduate in Electronic Information Engineering &nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2016
                - Present <br />
                GPA: <strong>92.98</strong>/100, &nbsp;&nbsp;Ranking: <strong>1/284</strong> (2018-2019) or
                <strong>1/415</strong> (first 2 years)<br />
                Advisors: Prof. <a href="https://interxuxing.github.io/">Xing Xu</a> and Prof. <a
                  href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>. &nbsp;&nbsp; Collaborated with Prof. <a
                  href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/multimedia-computing/people/alan-hanjalic/">Alan
                  Hanjalic</a>
              </p>
            </td>
          </tr>


          <tr>
            <td width="10%">
              <img src='image/chiba_icon.png' width="105">
            </td>

            <td width="90%" valign="middle">
              <p>
                <stronghuge>Chiba University, Japan</stronghuge><br />
                Exchange Program &nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &bull; Aug. 2017 <br />
                <a href="http://www.jst.go.jp/crcc/ssc/">Sakura Science Club Scholarship</a> awardee. Funded by Japan
                Science and Technology Agency <a href="http://www.jst.go.jp/EN/index.html">(JST)</a>.

              </p>
            </td>
          </tr>
        </table> -->

        <p></p>
        <p></p>
        <p></p>
        <p></p>
        <p></p>



        <p></p>
        <p></p>
        <p></p>
        <p></p>
        <p></p>

        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research Experience</heading>
            </td>
          </tr>
        </table> -->

        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="10%">
              <a href="http://cfm.uestc.edu.cn/">
                <img src='image/cfm_icon4.png' width="100">
              </a>
            </td>

            <td width="80%" valign="middle">
              <p>
                <stronghuge>Center For Future Media, UESTC</stronghuge><br />
                <huge><em>Research Assistant</em></huge>&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &bull; Mar. 2018 - Present
                <br />
                Advisors: &nbsp; Prof. <a href="https://interxuxing.github.io/">Xing Xu</a> and Prof. <a
                  href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>. &nbsp;&nbsp;Collaborated with Prof. <a
                  href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/multimedia-computing/people/alan-hanjalic/">Alan
                  Hanjalic</a><br />
                <li> Proposed several novel methods for cross-modal retrieval which achieves the state-of-the-art
                  performance on image-text matching.<br />
                <li> Comnined the GCN with Visual Question Generation Task and further boost the performance on an
                  unexplored challenging task zero-shot VQA. <br />
                <li> Complete 3 works and make the submission.
              </p>
            </td>
          </tr>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="10%">
                <a href="https://mreallab.github.io/people.html">
                  <img src='image/mreal_icon.png' width="100">
                </a>
              </td>

              <td width="80%" valign="middle">
                <p>
                  <stronghuge>MReal Lab, NTU</stronghuge><br />
                  <huge><em>Research Assistant</em></huge>&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &bull; July. 2019 - Present
                  <br />
                  Advisors: &nbsp; Prof. <a href="https://www.ntu.edu.sg/
/hanwangzhang/">Hanwang Zhang </a>
                </p>
              </td>
            </tr> -->


        <p></p>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>News</heading>
              <div style="line-height:25px">
                <p>
		  <li>
	            <em>(2023/09)</em> One paper for ABSA is accepted in <strong>Expert Systems with Application(ESWA) 2023</strong>.
		  <li>
	            <em>(2023/08)</em> One paper for Multimodal ERC is accepted in <strong>ACM MM 2023</strong>.
		  <li>
	             <em>(2023/06)</em> One paper for Multimodal ERC is accepted in <strong>Application Research in Computers(Chinese) 2023</strong>.
		  <li>
                    <em>(2022/10)</em> One paper for Multimodal ERC is accepted in <strong>Knowledge-Based Systems(KBS) 2022</strong>.
                  <li>
                    <em>(2022/04)</em> One paper for Aspect Term Extraction(ATE) is accepted in <strong>Journal of Chinese Computer Systems(Chinese) 2022</strong>.
<!--                   <li> -->
<!--                     <em>(2018/09)</em> I am a co-organizer of the Person in Context (<a href="http://picdataset.com/">PIC</a>) Workshop at ECCV2018.			   -->
                </p>
              </div>
            </td>
          </tr>
        </table>

        <p></p>
        <p></p>
        <p></p>
        <p></p>
        <p></p>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Selected Publications</heading>
            </td>
          </tr>
        </table>
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
    
            <td valign="top" width="100%">
              <strong>Multimodal Prompt Transformer with Hybrid Contrastive Learning for Emotion Recognition in Conversation</strong>
              
              <br>
              <strong><u>Shihao Zou</u></strong>,
              <a href="https://cs.cqut.edu.cn/info/1050/1310.htm">Xianying Huang</a>,
              Xudong Shen
              <br>
 
              <em>
                In Proceedings of the 31st ACM International Conference on Multimedia. <strong>ACM MM 2023</strong>.
                <br>
              </em>
                <a href="https://arxiv.org/abs/2310.04456"><strong>[Paper]</strong></a>
                <a
                  href="https://z-yolo.github.io/"><strong>[Code]</strong></a>
                  
                  <br>

               <em>
            </td>
          </tr>
        </table>
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
    
            <td valign="top" width="100%">
              <strong>Improving multimodal fusion with Main Modal Transformer for emotion recognition in conversation</strong>
              
              <br>
	      
              <strong><u>Shihao Zou</u></strong>,
	      Xianying Huang,
              Xudong Shen,
	      Hankai Liu
              <br>
 
              <em>
                 Knowledge-Based Systems. <strong>KBS 2022</strong>.
                <br>
              </em>
		    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0950705122010711"><strong>[Paper]</strong></a>
                    <a
                       href="https://z-yolo.github.io/"><strong>[Code]</strong></a>
                  
                  <br>

               <em>
            </td>
          </tr>
        </table>
	
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td valign="top" width="100%">
              <strong>PSAN: Prompt Semantic Augmented Network for aspect-based sentiment analysis</strong>
              
              <br>
              Ye He,
              Xianying Huang,
              <strong><u>Shihao Zou</u></strong>,
              Chengyang Zhang,
<!--               Bo Li,
              Shuicheng Yan -->
              <br>
              <em>
                Expert Systems with Applications. <strong>ESWA 2023</strong>.
                <br>
              </em>
                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417423021346"><strong>[Paper]</strong></a>
      
                  <br>
               <em>
            </td>
          </tr>
        </table>

	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td valign="top" width="100%">
              <strong>Multimodal Temporal-aware DAG for Emotion Recognition in Conversation</strong>
              
              <br>
              Xudong Shen,
              Xianying Huang,
              <strong><u>Shihao Zou</u></strong>
              <br>
              <em>
                Application Research in Computers(Chinese).2023.
                <br>
              </em>
<!--                 <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417423021346"><strong>[Paper]</strong></a> -->
      
                  <br>
               <em>
            </td>
          </tr>
        </table>

	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td valign="top" width="100%">
              <strong>Syntactic structure and semantic information fusion enhancement aspect eatraction method</strong>
              
              <br>
              Chaoyan Fu,
              Xianying Huang,
              <strong><u>Shihao Zou</u></strong>
              <br>
              <em>
                Journal of Chinese Information Processing(Chinese).2022.
                <br>
              </em>
<!--                 <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417423021346"><strong>[Paper]</strong></a> -->
      
                  <br>
               <em>
            </td>
          </tr>
        </table>

	      
<!-- 	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
    
            <td valign="top" width="100%">
              <strong>Reformulating HOI Detection as Adaptive Set Prediction</strong>
              
              <br>
	      Mingfei Chen*,
              <strong><u>Yue Liao*</u></strong>,
	      Si Liu,
              Zhiyuan Chen,
	      Fei Wang,
	      Chen Qian
              <br>
 
              <em>
                 IEEE International Conference on Computer Vision and Pattern Recognition. <strong>CVPR 2021</strong>.
                <br>
              </em>
		    <a href="https://arxiv.org/pdf/2103.05983.pdf"><strong>[Paper]</strong></a>
                    <a
                       href="https://github.com/yoyomimi/AS-Net"><strong>[Code]</strong></a>
                  
                  <br>

               <em>
            </td>
          </tr>
        </table> -->
	      
	<!--
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td valign="top" width="100%">
              <strong>Human-centric Spatio-Temporal Video Grounding With Visual Transformers</strong>
              
              <br>
              Zongheng Tang,
              <strong><u>Yue Liao</u></strong>,
              Si Liu,
	      Guanbin Li,
              Xiaojie Jin,
	      Hongxu Jiang,
	      Qian Yu,
              Dong Xu
              <br>
              <em>
                IEEE Transactions on Circuits and Systems for Video Technology. <strong>TCSVT 2021</strong>.
                <br>
              </em>
                <a href="https://arxiv.org/pdf/2011.05049"><strong>[Paper]</strong></a>
            
                  <br>

               <em>
            </td>
          </tr>
        </table>
	-->
	<!--
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
    
            <td valign="top" width="100%">
              <strong>Cross-Modal Omni Interaction Modeling for Phrase Grounding</strong>
              
              <br>
	      Tianyu Yu,
	      Tianrui Hui
	      Zhihao Yu,
              <strong><u>Yue Liao</u></strong>,
	      Si Liu,
              Sansi Yu,
	      Faxi Zhang 
              <br>
 
              <em>
                ACM Multimedia 2020. <strong>MM 2020</strong>.
                <br>
              </em>
          
		    <a href=" https://dl.acm.org/doi/pdf/10.1145/3394171.3413846"><strong>[Paper]</strong></a>
               
                  
                  <br>

               <em>
            </td>
          </tr>
        </table>
	-->
	<!--
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
    
            <td valign="top" width="100%">
              <strong>Local Correlation Consistency for Knowledge Distillation</strong>
              
              <br>
	      Xiaojie Li,
	      Jianlong Wu,
	      Hongyu Fang,
              <strong><u>Yue Liao</u></strong>,
	      Fei Wang,
              Chen Qian
              
              <br>
 
              <em>
                16th European Conference on Computer Vision. <strong>ECCV 2020</strong>.
                <br>
              </em>
                <a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570018.pdf"><strong>[Paper]</strong></a>
                  
                  <br>

               <em>
          
            </td>
          </tr>
        </table>
	-->
        



	<!--
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td valign="top" width="100%">
              <strong>A Real-Time Cross-modality Correlation Filtering Method for Referring Expression Comprehension</strong>
              <br>
              <strong><u>Yue Liao</u></strong>,
              <a href="http://colalab.org/people">Si Liu</a>,
              <a href="http://guanbinli.com/">Guanbin Li</a>,
              Fei Wang,
              Yanjie Chen,
              Chen Qian,
              Bo Li
              <br>
 
              <em>
                IEEE International Conference on Computer Vision and Pattern Recognition. <strong>CVPR 2020</strong>.
                <br>
              </em>
                <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Liao_A_Real-Time_Cross-Modality_Correlation_Filtering_Method_for_Referring_Expression_Comprehension_CVPR_2020_paper.pdf"><strong>[Paper]</strong></a>
		    
                  
                  <br>

               <em>
            </td>
          </tr>
        </table>
        -->


	<!--
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td valign="top" width="100%">
              <strong>CentripetalNet: Pursuing High-quality Keypoint Pairs for Object Detection</strong>
              <br>
              Zhiwei Dong,
              Guoxuan Li,
              <strong><u>Yue Liao</u></strong>,
              Fei Wang,
              Pengju Ren,
	      Chen Qian
              <br>
 
              <em>
                IEEE International Conference on Computer Vision and Pattern Recognition. <strong>CVPR 2020</strong>.
                <br>
              </em>
         
                <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Dong_CentripetalNet_Pursuing_High-Quality_Keypoint_Pairs_for_Object_Detection_CVPR_2020_paper.pdf"><strong>[Paper]</strong></a>
                 <a
                  href="https://github.com/KiveeDong/CentripetalNet"><strong>[Code]</strong></a> 
                  
                  <br>

               <em>
               
            </td>
          </tr>
        </table>
        -->
	<!--

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td valign="top" width="100%">
              <strong>Scene Graph Generation with Hierarchical Context</strong>
              
              <br>
              Guanghui Ren,
              Lejian Ren,
              <strong><u>Yue Liao</u></strong>,
              <a href="http://colalab.org/people">Si Liu</a>,
              Bo Li,
              Jizhong Han, 
              Shuicheng Yan
              <br>
 
              <em>
                IEEE Transactions on Neural Networks and Learning Systems. <strong>TNNLS 2020</strong>.
                <br>
              </em>
            
                <a href="http://colalab.org/media/paper/FINAL_VERSION.PDF"><strong>[Paper]</strong></a>
               
                  
                  <br>

               <em>
               
            </td>
          </tr>
        </table>
	-->
	<!--
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td valign="top" width="100%">
              <strong>GPS: GROUP PEOPLE SEGMENTATION WITH DETAILED PART INFERENCE</strong>
              
              <br>
              <strong><u>Yue Liao</u></strong>,
              <a href="http://colalab.org/people">Si Liu</a>,
              Tianrui Hui,
              Chen Gao, 
              Yao Sun,
              Hefei Ling,
              Bo Li
              <br>
 
              <em>
                International Conference on Multimedia and Expo. <strong>ICME 2019</strong>.
                <br>
              </em>
                <a href="http://colalab.org/media/paper/1231-camera-ready.pdf"><strong>[Paper]</strong></a>
               
                  
                  <br>

               <em>
                <strong>
                  <font color="#a82e2e">(Oral Presentation)</font>
                </strong></em> <br> 

             
            </td>
          </tr>
        </table>
	-->
        
        

        <p></p>
        <p></p>
        <p></p>
        <p></p>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Awards</heading>
              <div style="line-height:25px">
                <p>
                  <li>
                    National Scholarship, Chongqing University of Technology,&nbsp; 2023<br />
                  <li>
                    Merit Student, Advanced Individuals of Innovation, Chongqing University of Technology ,&nbsp;
                    2023<br />
                  <li>
                    National Encouragement Scholarship, Pingdingshan University ,&nbsp; 2020<br />
<!--                   <li>
                    National Scholarship, Xidian University (Top 1%),&nbsp; 2015<br /> -->
                </p>
              </div>
            </td>
          </tr>
        </table>


        <center>
          <a href="https://clustrmaps.com/site/1bhe3"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=7jyPsD6c0yeMvDnTroUk7eWGtwLtuJgTu-xEVYc_DEk&cl=ffffff" /></a>
        </center>

</body>

</html>
